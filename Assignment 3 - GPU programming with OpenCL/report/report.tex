\documentclass[12pt]{article}

\usepackage[letterpaper, hmargin=0.75in, vmargin=0.75in]{geometry}
\usepackage{float}
\usepackage{listings}

\pagestyle{empty}

\title{ECE 459: Programming for Performance\\Assignment 3}
\author{Zhidong Zhang}
\date{\today}

% Code listing style
\lstset{frame=single}

\begin{document}

\maketitle

\section*{Part 1: Crack it to me}

\begin{enumerate}
\item Design Choices:
   \begin{itemize}
     \item If the secret length is x and the number of possible characters is 36, then the number of possible secrets is $36^x$. For the secret length of x, the problem size is $36^x$, which can be set as the global work size of the kernel. In the kernel, get\_global\_id(0) returns a global id from 0 to $36^x - 1$. We can create a Base36 decoder to decode the global id into a possible secret with length x. In the same kernel, I verify the correctness of the possible secret by comparing the original signature and the current signature generated by the HMAC\_SHA256 function. If the secret is correct, I will write the secret into the output buffer. 
   \end{itemize}
   \begin{itemize}
     \item In the main.cpp, the JWT secret's max length is given as the gMaxSecretLen. Therefore, possible secret lengths are ranging from $[1: gMaxSecretLen]$. To find the secret, for each possible secret length $x \in [1: gMaxSecretLen]$, I run the kernel separately with the global size set to $36^x$. 
   \end{itemize}
\item Results:

\\
\\
$\begin{array}{ | l | l | l | l | l | }
\hline
	 & jwtcracker\_sin & jwtcracker\_omp & jwtcracker\_ocl \\ \hline
	MaxSecretLen = 4 & 2.593 & \textbf{0.185s} & 1.424s \\ \hline
	MaxSecretLen = 5 & 102.06s & 7.444s & \textbf{3.284s} \\ \hline
	MaxSecretLen = 6 & 4104s & 306s & \textbf{75s} \\ \hline
\end{array}$ \\
\item Speed up explanation
   \begin{itemize}
     \item Here are the speedups observed from the above table. When the maxSecretLen is 4, jwtcracker\_omp is the fastest. This is because jwtcracker\_ocl spawning $36^4$ number of threads whose overhead outweigh its speedup when the maxSecretLen is small.  When the maxSecretLen is 5, jwtcracker\_ocl is the fastest, which has 31 times speedup compared with jwtcracker\_ocl and 2 times speedup compared with jwtcracker\_omp. When the maxSecretLen is 6, jwtcracker\_ocl is the fastest, which has 55 times speedup compared with jwtcracker\_ocl and 4 times speedup compared with jwtcracker\_omp. This is expected. When the secret length is longer, OpenCL shows a significant advantage over OpenMP, because all the threads or work items are distributed and parallelized by the 2560 CUDA Cores in the GPU. 
   \end{itemize}
\end{enumerate}

\section*{Part 2: Coulombâ€™s Law Problem}

\begin{enumerate}
\item Design Choices:
   \begin{itemize}
     \item In the OpenMP code, functions computeForces(), computeApproxPositions(), computeBetterPositions() and isErrorAcceptable() is applied with openMp parallel-for directive, which enables parallization. Therefore, in the OpenCL open, I need to transfer those functions into different kernels functions. I created three kernel functions which are computeForces(), computePositions(), isErrorAcceptable(), whose global work size is set to the total number of particles. In each kernel, get\_global\_id(0) returns the global id which is the particle id or particle index. Each kernel uses the particle id to compute the property just for that particle. 
     \item In Simulation::run() function, I substituted all openMP function calls with kernels calls, and created buffers and arguments correctly. 
   \end{itemize}
\item Results:
\\
\\
$\begin{array}{ | l | l | l | l | l | }
\hline
	 & protons\_sin & protons\_omp & protons\_ocl \\ \hline
	numProtons = 25, numElections = 25 & \textbf{0.025s} & 3.570s & 1.114s \\ \hline
	numProtons = 500, numElections = 500 & 4.541 & 4.809s & \textbf{1.186s} \\ \hline
	numProtons = 1000, numElections = 1000 & 16.347s & 5.905s & \textbf{1.532s} \\ \hline
	numProtons = 2500, numElections = 2500 & 109.609s & 17.624s & \textbf{2.075s} \\ \hline
	numProtons = 5000, numElections = 5000 & 441.628s & 56.321s & \textbf{3.145s} \\ \hline
	numProtons = 7500, numElections = 7500 & 997.164s & 109.303s & \textbf{4.265s} \\ \hline
	numProtons = 10000, numElections = 10000 & 1998.533s & 202.066s & \textbf{5.216s} \\ \hline
\end{array}$ \\
\item Speed up explanation
   \begin{itemize}
     \item From the above results, when the number of particles is small, the protons\_sin works the best because it has the lowest overhead. However, when the number of particles is bigger (over 500), the protons\_ocl shows a significant advantage over protons\_omp and protons\_sin by achieving more speed up as the number of particles increases. Especially, when the total number of elections is 10000, protons\_ocl has around 400 times speedup over the single-thread solution and 40 times speedup over the OpenMP solution. This is as expected. When the number of particles is small, the GPU is under-utilized. As the number of particles increases by x time, the protons\_sin's and protons\_omp's execution time increase by $x^2$ time, whereas, the protons\_ocl's execution time only increase by x time, because the outer loop of function computeForce() and computerPositions() are fully parallelized on the GPU. 
   \end{itemize}
\end{enumerate}

\end{document}
